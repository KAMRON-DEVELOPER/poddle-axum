logging {
	level  = "info"
	format = "logfmt"
}

// ---------------------------------------------------------
// 1. APP METRICS SCRAPING (Clustered)
// ---------------------------------------------------------
discovery.kubernetes "pods" {
	role = "pod"
}

discovery.relabel "app_metrics" {
	targets = discovery.kubernetes.pods.targets

	// Only scrape pods with annotation
	rule {
		source_labels = ["__meta_kubernetes_pod_annotation_prometheus_io_scrape"]
		action        = "keep"
		regex         = "true"
	}

	// Handle custom ports
	rule {
		source_labels = ["__address__", "__meta_kubernetes_pod_annotation_prometheus_io_port"]
		action        = "replace"
		regex         = "([^:]+)(?::\\d+)?;(\\d+)"
		replacement   = "$1:$2"
		target_label  = "__address__"
	}
    
    // Custom Labels
	rule { source_labels = ["__meta_kubernetes_pod_label_project_id"], target_label = "project_id" }
	rule { source_labels = ["__meta_kubernetes_pod_label_deployment_id"], target_label = "deployment_id" }
	rule { source_labels = ["__meta_kubernetes_namespace"], target_label = "namespace" }
	rule { source_labels = ["__meta_kubernetes_pod_label_app"], target_label = "app" }
}

prometheus.scrape "default" {
	targets         = discovery.relabel.app_metrics.output
	forward_to      = [prometheus.remote_write.default.receiver]
	scrape_interval = "15s"
	clustering {
		enabled = true // Distributes scrape targets across the 2 replicas
	}
}

// ---------------------------------------------------------
// 2. OTLP RECEIVER (Traces)
// ---------------------------------------------------------
otelcol.receiver.otlp "default" {
	grpc { endpoint = "0.0.0.0:4317" }
	http { endpoint = "0.0.0.0:4318" }

	output {
		metrics = [otelcol.processor.batch.default.input]
		traces  = [otelcol.processor.batch.default.input]
	}
}

// Enrich traces with K8s metadata using the Pod IP
otelcol.processor.k8sattributes "default" {
	extract {
		metadata = ["k8s.namespace.name", "k8s.pod.name", "k8s.deployment.name"]
	}
	pod_association {
		source { from = "connection" }
	}
	output {
		metrics = [otelcol.processor.batch.default.input]
		traces  = [otelcol.processor.batch.default.input]
	}
}

otelcol.processor.batch "default" {
	output {
		metrics = [otelcol.exporter.prometheus.default.input]
		traces  = [otelcol.exporter.otlp.tempo.input]
	}
}

// ---------------------------------------------------------
// 3. EXPORTERS
// ---------------------------------------------------------
otelcol.exporter.prometheus "default" {
	forward_to = [prometheus.remote_write.default.receiver]
}

prometheus.remote_write "default" {
	endpoint {
		url = "http://prometheus-server.prometheus.svc.cluster.local:80/api/v1/write"
	}
}

otelcol.exporter.otlp "tempo" {
	client {
		endpoint = "tempo.tempo.svc.cluster.local:4317"
		tls {
			insecure = true
		}
	}
}

// =======================================================
// 1. CLUSTERED SCRAPING (The "Pull" Model)
// =======================================================
discovery.kubernetes "pods" { role = "pod" }

discovery.relabel "app_metrics" {
    targets = discovery.kubernetes.pods.targets
    // ... keep rules (prometheus.io/scrape = true) ...
    // ... metadata label rules ...
}

prometheus.scrape "default" {
    targets = discovery.relabel.app_metrics.output
    clustering { enabled = true } // THIS is why we use StatefulSet. It shares the load.
    forward_to = [prometheus.remote_write.default.receiver]
}

// =======================================================
// 2. OTLP RECEIVER (The "Push" Model)
// =======================================================
otelcol.receiver.otlp "default" {
    grpc { endpoint = "0.0.0.0:4317" }
    http { endpoint = "0.0.0.0:4318" }
    
    output {
        // Rust apps sending metrics via OTLP go here
        metrics = [otelcol.processor.batch.default.input]
        // Rust apps sending traces via OTLP go here
        traces  = [otelcol.processor.batch.default.input]
    }
}

// Enrich data with K8s metadata (Project IDs, etc)
otelcol.processor.k8sattributes "default" {
    extract {
        metadata = ["k8s.namespace.name", "k8s.pod.name", "k8s.deployment.name"]
    }
    pod_association {
        source { from = "connection" } // Map IP to Pod
    }
    output {
        metrics = [otelcol.processor.batch.default.input]
        traces  = [otelcol.processor.batch.default.input]
    }
}

otelcol.processor.batch "default" {
    output {
        metrics = [otelcol.exporter.prometheus.default.input] // Convert OTLP metrics to Prometheus
        traces  = [otelcol.exporter.otlp.tempo.input]        // Send traces to Tempo
    }
}

// =======================================================
// 3. EXPORTERS
// =======================================================

// Convert OTLP Metrics -> Prometheus Remote Write
otelcol.exporter.prometheus "default" {
    forward_to = [prometheus.remote_write.default.receiver]
}

prometheus.remote_write "default" {
    endpoint { url = "http://prometheus-server.prometheus.svc.cluster.local:80/api/v1/write" }
}

otelcol.exporter.otlp "tempo" {
    client {
        endpoint = "tempo.tempo.svc.cluster.local:4317"
        tls { insecure = true }
    }
}