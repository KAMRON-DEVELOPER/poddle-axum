logging {
	level  = "info"
	format = "logfmt"
}

// ---------------------------------------------------------------------------------
// OTLP RECEIVERS (Accept telemetry from agents and applications) 
// ---------------------------------------------------------------------------------

otelcol.receiver.otlp "default" {
	grpc {
		endpoint = "0.0.0.0:4317"
	}

	http {
		endpoint = "0.0.0.0:4318"
	}

	output {
		// Forward everything to memory limiter first
		metrics = [otelcol.processor.memory_limiter.default.input]
		traces  = [otelcol.processor.memory_limiter.default.input]
		logs    = [otelcol.processor.memory_limiter.default.input]
	}
}

// ---------------------------------------------------------
// PROCESSORS
// ---------------------------------------------------------

// Memory Limiter - Protection against OOM
otelcol.processor.memory_limiter "default" {
	check_interval         = "3s"
	limit_percentage       = 80 // 80% of 800Mi
	spike_limit_percentage = 20 // Conservative for low-resource cluster

	output {
		metrics = [otelcol.processor.k8sattributes.default.input]
		traces  = [otelcol.processor.k8sattributes.default.input]
		logs    = [otelcol.processor.k8sattributes.default.input]
	}
}

// K8s Attributes - Enrich data with K8s metadata
otelcol.processor.k8sattributes "default" {
	// Extract metadata from pods
	extract {
		metadata = [
			"k8s.namespace.name",
			"k8s.pod.name",
			"k8s.pod.uid",
			"k8s.deployment.name",
			"k8s.node.name",
		]

		// Extract custom PaaS labels (matching Rust backend labels)
		label {
			from     = "pod"
			key      = "app"
			tag_name = "app"
		}

		label {
			from     = "pod"
			key      = "project-id"
			tag_name = "project_id"
		}

		label {
			from     = "pod"
			key      = "deployment-id"
			tag_name = "deployment_id"
		}

		label {
			from     = "pod"
			key      = "managed-by"
			tag_name = "managed_by"
		}
	}

	// Configure pod association strategies
	pod_association {
		source {
			from = "resource_attribute"
			name = "k8s.pod.ip"
		}
	}

	pod_association {
		source {
			from = "resource_attribute"
			name = "k8s.pod.uid"
		}
	}

	pod_association {
		source {
			from = "connection"
		}
	}

	output {
		// Metrics: transform then batch
		metrics = [otelcol.processor.transform.default.input]
		// Traces: {tail_sampling|spanmetrics} -> batch
		traces = [
			otelcol.connector.spanmetrics.default.input, // RED metrics
			otelcol.connector.servicegraph.default.input, // Service graph
			otelcol.processor.tail_sampling.default.input, // Sampling
		]
		// Logs: straight to batch
		logs = [otelcol.processor.batch.default.input]
	}
}

// Transform - Convert resource â†’ datapoint attributes for Prometheus
otelcol.processor.transform "default" {
	error_mode = "ignore"

	metric_statements {
		context    = "datapoint"
		statements = [
			// Promote resource attributes to datapoint attributes for Prometheus labels
			"set(attributes[\"namespace\"], resource.attributes[\"k8s.namespace.name\"])",
			"set(attributes[\"pod\"], resource.attributes[\"k8s.pod.name\"])",
			"set(attributes[\"deployment\"], resource.attributes[\"k8s.deployment.name\"])",
			"set(attributes[\"node\"], resource.attributes[\"k8s.node.name\"])",
			"set(attributes[\"app\"], resource.attributes[\"app\"])",
			"set(attributes[\"project_id\"], resource.attributes[\"project_id\"])",
			"set(attributes[\"deployment_id\"], resource.attributes[\"deployment_id\"])",
			"set(attributes[\"managed_by\"], resource.attributes[\"managed_by\"])",
		]
	}

	output {
		metrics = [otelcol.processor.batch.default.input]
	}
}

// Tail Sampling - Reduce trace volume (Trace Exporter)
otelcol.processor.tail_sampling "default" {
	// How long to wait for all spans of a trace
	decision_wait = "10s"
	// Max traces to keep in memory
	num_traces = 1000

	// Sample errors at 100%
	policy {
		name = "errors"
		type = "status_code"

		status_code {
			status_codes = ["ERROR"]
		}
	}

	// Sample slow traces (>1s) at 100%
	policy {
		name = "slow"
		type = "latency"

		latency {
			threshold_ms = 1000
		}
	}

	// Sample 10% of normal traces
	policy {
		name = "normal"
		type = "probabilistic"

		probabilistic {
			sampling_percentage = 10
		}
	}

	// Always sample traces for specific services (add as needed)
	// policy {
	// 	name = "sample-critical-services"
	// 	type = "string_attribute"
	// 	string_attribute {
	// 		key    = "service.name"
	// 		values = ["critical-api", "payment-service"]
	// 	}
	// }

	output {
		// tail_sampling -> batch
		traces = [otelcol.processor.batch.default.input]
	}
}

// Batch - Efficient sending the telemetry
otelcol.processor.batch "default" {
	send_batch_size     = 1000
	send_batch_max_size = 2000
	timeout             = "5s"

	output {
		metrics = [otelcol.exporter.prometheus.default.input]
		logs    = [otelcol.exporter.loki.default.input]
		traces  = [otelcol.exporter.otlp.tempo.input]
	}
}

// ---------------------------------------------------------------------------------
// CONNECTORS
// ---------------------------------------------------------------------------------

otelcol.connector.servicegraph "default" {
	latency_histogram_buckets = ["10ms", "50ms", "100ms", "250ms", "500ms", "1s", "2.5s", "5s", "10s"]
	dimensions                = ["http.method", "http.status_code", "service.name"]

	store {
		ttl       = "3s"
		max_items = 200
	}

	output {
		metrics = [otelcol.processor.batch.default.input]
	}
}

// Spanmetrics Connector - Generates RED metrics from Traces (Metric Exporter)
otelcol.connector.spanmetrics "default" {
	// Histogram buckets for latency (in milliseconds)
	histogram {
		explicit {
			buckets = ["10ms", "50ms", "100ms", "250ms", "500ms", "1s", "2.5s", "5s"]
		}
	}

	// Add extra dimensions to your metrics from span attributes
	dimension {
		name = "http.method"
	}

	dimension {
		name = "http.status_code"
	}

	dimension {
		name = "service.name"
	}

	output {
		metrics = [otelcol.processor.batch.default.input]
	}
}

// ---------------------------------------------------------------------------------
// KUBE-STATE-METRICS (Cluster Level)
// ---------------------------------------------------------------------------------

// Discover the kube-state-metrics service
discovery.kubernetes "kube_state_metrics" {
	role = "service"

	namespaces {
		names = ["kube-system"]
	}

	selectors {
		role  = "service"
		label = "app.kubernetes.io/name=kube-state-metrics"
	}
}

prometheus.scrape "kube_state_metrics" {
	targets  = discovery.kubernetes.kube_state_metrics.targets
	scheme   = "http"
	job_name = "kube-state-metrics"

	forward_to = [prometheus.remote_write.default.receiver]
}

// ---------------------------------------------------------------------------------
// EXPORTERS
// ---------------------------------------------------------------------------------

// Metrics -> Prometheus
otelcol.exporter.prometheus "default" {
	forward_to = [prometheus.remote_write.default.receiver]
}

prometheus.remote_write "default" {
	endpoint {
		url = "http://prometheus-server.prometheus.svc.cluster.local:80/api/v1/write"

		// Queue configuration for high throughput
		queue_config {
			capacity             = 2500
			max_shards           = 5
			min_shards           = 1
			max_samples_per_send = 1000
			batch_send_deadline  = "5s"
			min_backoff          = "30ms"
			max_backoff          = "5s"
		}
	}
}

// Traces -> Tempo
otelcol.exporter.otlp "tempo" {
	client {
		endpoint = "tempo.tempo.svc.cluster.local:4317"

		tls {
			insecure             = true
			insecure_skip_verify = true
		}

		// Connection settings
		balancer_name = "round_robin"
		compression   = "gzip"
	}

	// Queue settings
	sending_queue {
		enabled       = true
		num_consumers = 5
		queue_size    = 500
	}
}

// Logs -> Loki
otelcol.exporter.loki "default" {
	forward_to = [loki.write.default.receiver]
}

loki.write "default" {
	endpoint {
		url = "http://loki.loki.svc.cluster.local:3100/loki/api/v1/push"

		batch_size = "1MiB"

		batch_wait = "5s"
	}

	// External labels for all logs
	external_labels = {
		cluster = "alloy-gateway-cluster",
	}
}
