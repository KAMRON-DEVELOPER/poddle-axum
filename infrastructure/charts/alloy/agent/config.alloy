logging {
	level  = "info"
	format = "logfmt"
}

// ---------------------------------------------------------
// LOGS COLLECTION
// ---------------------------------------------------------

discovery.kubernetes "pods" {
	role = "pod"

	selectors {
		role  = "pod"
		field = "spec.nodeName=" + coalesce(env("NODE_NAME"), constants.hostname)
	}
}

discovery.relabel "local_pod_log_paths" {
	targets = discovery.kubernetes.pods.targets

	// Construct the path to the log file on the host
	// Path format: /var/log/pods/<namespace>_<pod_name>_<uid>/<container_name>/*.log
	rule {
		source_labels = ["__meta_kubernetes_namespace", "__meta_kubernetes_pod_name", "__meta_kubernetes_pod_uid", "__meta_kubernetes_pod_container_name"]
		target_label  = "__path__"
		separator     = "/"
		replacement   = "/var/log/pods/*_*_$3/$4/*.log"
	}

	// Standard Labels
	rule {
		source_labels = ["__meta_kubernetes_namespace"]
		target_label  = "namespace"
	}

	rule {
		source_labels = ["__meta_kubernetes_pod_name"]
		target_label  = "pod"
	}

	rule {
		source_labels = ["__meta_kubernetes_pod_container_name"]
		target_label  = "container"
	}

	rule {
		source_labels = ["__meta_kubernetes_pod_label_app"]
		target_label  = "app"
	}

	// Custom Labels
	rule {
		source_labels = ["__meta_kubernetes_pod_label_project_id"]
		target_label  = "project_id"
	}

	rule {
		source_labels = ["__meta_kubernetes_pod_label_deployment_id"]
		target_label  = "deployment_id"
	}

	rule {
		source_labels = ["__meta_kubernetes_pod_label_managed_by"]
		target_label  = "managed_by"
	}
}

// Read the files directly from disk (Efficient!)
loki.source.file "pods" {
	targets    = discovery.relabel.local_pod_log_paths.output
	forward_to = [loki.process.default.receiver]
}

loki.process "default" {
	forward_to = [loki.write.default.receiver]

	// Tag everything as containerd (since Poddle is on K3s/Cilium)
	stage.static_labels {
		values = {
			tmp_container_runtime = "containerd",
		}
	}

	stage.json {
		expressions = {
			level    = "level",
			trace_id = "trace_id",
			msg      = "message",
			time     = "timestamp",
		}
	}

	// Promotes level from extracted field â†’ Loki label
	// You can filter {level="error"} in Loki, Improves query ergonomics
	stage.labels {
		values = {
			level    = "level",
			trace_id = "trace_id",
		}
	}

	stage.match {
		selector = "{tmp_container_runtime=\"containerd\"}"

		stage.cri { }

		stage.labels {
			values = {
				flags  = "",
				stream = "",
			}
		}
	}

	stage.match {
		selector = "{tmp_container_runtime=\"docker\"}"

		stage.docker { }

		stage.labels {
			values = {
				stream = "",
			}
		}
	}

	// Cleanup temporary labels
	stage.label_drop {
		values = ["tmp_container_runtime"]
	}
}

loki.write "default" {
	endpoint {
		url = "http://loki.loki.svc.cluster.local:3100/loki/api/v1/push"
	}
}

// ---------------------------------------------------------
// CONTAINER METRICS (via kubelet's built-in cAdvisor)
// ---------------------------------------------------------

// Discover all nodes in the cluster
discovery.kubernetes "nodes" {
	role = "node"
}

// Relabel to construct kubelet metrics endpoint
discovery.relabel "cadvisor" {
	targets = discovery.kubernetes.nodes.targets

	// Keep only the current node
	rule {
		source_labels = ["__meta_kubernetes_node_name"]
		regex         = env("NODE_NAME")
		action        = "keep"
	}

	// Use the node's internal IP
	rule {
		source_labels = ["__address__"]
		replacement   = "$1:10250"
		target_label  = "__address__"
	}

	// Set the metrics path to kubelet's cAdvisor endpoint
	rule {
		replacement  = "/metrics/cadvisor"
		target_label = "__metrics_path__"
	}

	// Set scheme to https (kubelet uses TLS)
	rule {
		replacement  = "https"
		target_label = "__scheme__"
	}

	// Add node label
	rule {
		source_labels = ["__meta_kubernetes_node_name"]
		target_label  = "node"
	}
}

// Scrape container metrics from kubelet
prometheus.scrape "cadvisor" {
	targets           = discovery.relabel.cadvisor.output
	job_name          = "cadvisor"
	scheme            = "https"
	bearer_token_file = "/var/run/secrets/kubernetes.io/serviceaccount/token"

	tls_config {
		ca_file = "/var/run/secrets/kubernetes.io/serviceaccount/ca.crt"

		// K3s certs often don't validate against the Pod CA perfectly
		// Disabling verification is safe for internal cluster scraping

		// K3s generates self-signed certificates for its Kubelets.
		// Alloy cannot verify them against a public CA, so it refuses to scrape, resulting in zero metrics.
		insecure_skip_verify = true
	}

	forward_to = [prometheus.remote_write.default.receiver]
}

// ---------------------------------------------------------
// HOST/NODE METRICS
// ---------------------------------------------------------

prometheus.exporter.unix "host" {
	rootfs_path = "/host/root"
	procfs_path = "/host/proc"
	sysfs_path  = "/host/sys"

	// set_collectors = ["cpu", "diskstats", "filesystem", "loadavg", "meminfo", "netdev", "stat", "time", "uname"]
}

prometheus.scrape "node" {
	targets    = prometheus.exporter.unix.host.targets
	job_name   = "node"
	forward_to = [prometheus.remote_write.default.receiver]
}

// ---------------------------------------------------------
// REMOTE WRITE
// ---------------------------------------------------------

prometheus.remote_write "default" {
	endpoint {
		url = "http://prometheus-server.prometheus.svc.cluster.local:80/api/v1/write"
	}
}
